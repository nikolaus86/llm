# app.py
import streamlit as st
import json
import pandas as pd
from datetime import datetime
import requests
import os
from typing import Optional, Dict, List
import warnings
import PyPDF2
import io
from docx import Document
import tempfile
warnings.filterwarnings("ignore")

class DataCollectionManager:
    def __init__(self, data_dir: str = "evaluation_data"):
        self.data_dir = data_dir
        self.dialogs_dir = os.path.join(data_dir, "dialogs")
        self.system_prompts_file = os.path.join(data_dir, "system_prompts.json")
        self.summary_file = os.path.join(data_dir, "evaluation_summary.csv")
        self.materials_dir = os.path.join(data_dir, "materials")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        os.makedirs(self.dialogs_dir, exist_ok=True)
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.materials_dir, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        self._initialize_files()
    
    def _initialize_files(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
        # –§–∞–π–ª —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
        if not os.path.exists(self.system_prompts_file):
            with open(self.system_prompts_file, 'w', encoding='utf-8') as f:
                json.dump([], f, ensure_ascii=False, indent=2)
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª –æ—Ç—á–µ—Ç–∞
        if not os.path.exists(self.summary_file):
            df = pd.DataFrame(columns=[
                'model_name', 'model_parameters', 'lecture_title', 
                'lecture_topic', 'system_prompt_id', 'dialog_id',
                'overall_rating', 'evaluation_notes'
            ])
            df.to_csv(self.summary_file, index=False, encoding='utf-8')
    
    def save_system_prompt(self, prompt_data: Dict):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞"""
        try:
            with open(self.system_prompts_file, 'r', encoding='utf-8') as f:
                prompts = json.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–π prompt_id
            existing_ids = [p['system_prompt_id'] for p in prompts]
            if prompt_data['system_prompt_id'] not in existing_ids:
                prompts.append(prompt_data)
                
                with open(self.system_prompts_file, 'w', encoding='utf-8') as f:
                    json.dump(prompts, f, ensure_ascii=False, indent=2)
            
            return True
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞: {e}")
            return False
    
    def save_dialog_data(self, dialog_id: str, dialog_data: List[Dict]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–∞ –≤ JSON –∏ CSV"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
            dialog_file_json = os.path.join(self.dialogs_dir, f"{dialog_id}.json")
            with open(dialog_file_json, 'w', encoding='utf-8') as f:
                json.dump(dialog_data, f, ensure_ascii=False, indent=2)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
            dialog_file_csv = os.path.join(self.dialogs_dir, f"{dialog_id}.csv")
            df_dialog = pd.DataFrame(dialog_data)
            df_dialog.to_csv(dialog_file_csv, index=False, encoding='utf-8')
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel
            dialog_file_xlsx = os.path.join(self.dialogs_dir, f"{dialog_id}.xlsx")
            df_dialog.to_excel(dialog_file_xlsx, index=False)
            
            return True
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞: {e}")
            return False
    
    def save_evaluation_summary(self, summary_data: Dict):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏ –¥–∏–∞–ª–æ–≥–∞"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            if os.path.exists(self.summary_file):
                df = pd.read_csv(self.summary_file)
            else:
                df = pd.DataFrame(columns=[
                    'model_name', 'model_parameters', 'lecture_title', 
                    'lecture_topic', 'system_prompt_id', 'dialog_id',
                    'overall_rating', 'evaluation_notes'
                ])
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
            new_row = pd.DataFrame([summary_data])
            df = pd.concat([df, new_row], ignore_index=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
            df.to_csv(self.summary_file, index=False, encoding='utf-8')
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel
            summary_file_xlsx = os.path.join(self.data_dir, "evaluation_summary.xlsx")
            df.to_excel(summary_file_xlsx, index=False)
            
            return True
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏: {e}")
            return False
    
    def save_system_prompts_export(self):
        """–≠–∫—Å–ø–æ—Ä—Ç —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –≤ CSV –∏ Excel"""
        try:
            with open(self.system_prompts_file, 'r', encoding='utf-8') as f:
                prompts = json.load(f)
            
            if prompts:
                df_prompts = pd.DataFrame(prompts)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
                prompts_csv = os.path.join(self.data_dir, "system_prompts.csv")
                df_prompts.to_csv(prompts_csv, index=False, encoding='utf-8')
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel
                prompts_xlsx = os.path.join(self.data_dir, "system_prompts.xlsx")
                df_prompts.to_excel(prompts_xlsx, index=False)
                
                return True
            return False
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤: {e}")
            return False
    
    def save_uploaded_file(self, file, filename: str) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        try:
            file_path = os.path.join(self.materials_dir, filename)
            with open(file_path, 'wb') as f:
                f.write(file.getbuffer())
            return file_path
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            return ""
    
    def get_next_dialog_id(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ ID –¥–∏–∞–ª–æ–≥–∞"""
        try:
            if os.path.exists(self.summary_file):
                df = pd.read_csv(self.summary_file)
                if len(df) == 0:
                    return "dialog0001"
                else:
                    last_id = df['dialog_id'].iloc[-1]
                    number = int(last_id.replace('dialog', '')) + 1
                    return f"dialog{number:04d}"
            return "dialog0001"
        except:
            return "dialog0001"
    
    def get_next_prompt_id(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ ID —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞"""
        try:
            if os.path.exists(self.system_prompts_file):
                with open(self.system_prompts_file, 'r', encoding='utf-8') as f:
                    prompts = json.load(f)
                
                if not prompts:
                    return "prompt0001"
                else:
                    existing_ids = [p['system_prompt_id'] for p in prompts]
                    if not existing_ids:
                        return "prompt0001"
                    last_id = max(existing_ids)
                    number = int(last_id.replace('prompt', '')) + 1
                    return f"prompt{number:04d}"
            return "prompt0001"
        except:
            return "prompt0001"
    
    def get_all_system_prompts(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤"""
        try:
            with open(self.system_prompts_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []

class FileProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    
    @staticmethod
    def extract_text_from_pdf(file) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF —Ñ–∞–π–ª–∞"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–∑–∏—Ü–∏—é —Ñ–∞–π–ª–∞
            current_position = file.tell()
            file.seek(0)
            
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–∑–∏—Ü–∏—é —Ñ–∞–π–ª–∞
            file.seek(current_position)
            return text
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF: {e}")
            return ""
    
    @staticmethod
    def extract_text_from_txt(file) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ TXT —Ñ–∞–π–ª–∞"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–∑–∏—Ü–∏—é —Ñ–∞–π–ª–∞
            current_position = file.tell()
            file.seek(0)
            
            text = file.getvalue().decode('utf-8')
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–∑–∏—Ü–∏—é —Ñ–∞–π–ª–∞
            file.seek(current_position)
            return text
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è TXT: {e}")
            return ""
    
    @staticmethod
    def extract_text_from_docx(file) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOCX —Ñ–∞–π–ª–∞"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–∑–∏—Ü–∏—é —Ñ–∞–π–ª–∞
            current_position = file.tell()
            file.seek(0)
            
            doc = Document(file)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–∑–∏—Ü–∏—é —Ñ–∞–π–ª–∞
            file.seek(current_position)
            return text
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX: {e}")
            return ""

class NeuralNetworkManager:
    def __init__(self):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫—Ä—ã—Ç—ã–µ –º–æ–¥–µ–ª–∏
        self.available_models = {
            "HuggingFace": {
                "Qwen-2.5-1.5B": {"path": "Qwen/Qwen2.5-1.5B", "params": "1.5B"},
                "Microsoft-DialoGPT-medium": {"path": "microsoft/DialoGPT-medium", "params": "0.8B"},
                "GPT-2-Medium": {"path": "gpt2-medium", "params": "0.8B"},
                "DistilGPT-2": {"path": "distilgpt2", "params": "0.3B"},
                "TinyLlama-1.1B": {"path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0", "params": "1.1B"}
            },
            "Ollama": {
                "Llama-3.2-3B": {"path": "llama3.2:3b", "params": "3B"},
                "Qwen-2.5-1.5B": {"path": "qwen2.5:1.5b", "params": "1.5B"}, 
                "Gemma-2-2B": {"path": "gemma2:2b", "params": "2B"},
                "TinyLlama-1.1B": {"path": "tinyllama:1.1b", "params": "1.1B"}
            },
            "OpenRouter": {
                "Mistral-7B": {"path": "mistralai/mistral-7b-instruct:free", "params": "7B"},
                "Google-Gemma-7B": {"path": "google/gemma-7b-it:free", "params": "7B"}
            }
        }
        self.current_provider = None
        self.current_model = None
        self.current_model_name = None
        self.current_model_params = None
        
    def setup_huggingface(self, model_name: str):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ HuggingFace —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"""
        try:
            from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
            import torch
            
            model_info = self.available_models["HuggingFace"][model_name]
            model_path = model_info["path"]
            
            st.info(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å {model_name}... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∞–∑–µ—Ä –∏ –º–æ–¥–µ–ª—å
            tokenizer = AutoTokenizer.from_pretrained(model_path)
            
            # –î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å pad_token
            if tokenizer.pad_token is None:
                tokenizer.pad_token = tokenizer.eos_token
            
            model = AutoModelForCausalLM.from_pretrained(
                model_path,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else None,
                low_cpu_mem_usage=True,
                trust_remote_code=True
            )
            
            # –°–æ–∑–¥–∞–µ–º pipeline
            pipe = pipeline(
                "text-generation",
                model=model,
                tokenizer=tokenizer,
                max_new_tokens=512,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1,
                pad_token_id=tokenizer.eos_token_id
            )
            
            self.current_provider = "huggingface_local"
            self.current_model = pipe
            self.current_model_name = model_name
            self.current_model_params = model_info["params"]
            return True
                
        except ImportError:
            st.error("‚ùå –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è HuggingFace —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install transformers torch accelerate")
            return False
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
            return False
    
    def setup_ollama(self, model_name: str, base_url: str = "http://localhost:11434"):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
            response = requests.get(f"{base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                available_models = [model["name"] for model in response.json().get("models", [])]
                model_info = self.available_models["Ollama"][model_name]
                selected_model = model_info["path"]
                
                if selected_model in available_models:
                    self.current_provider = "ollama"
                    self.current_model = selected_model
                    self.current_model_name = model_name
                    self.current_model_params = model_info["params"]
                    self.ollama_url = base_url
                    return True
                else:
                    st.error(f"‚ùå –ú–æ–¥–µ–ª—å {selected_model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ Ollama. –°–∫–∞—á–∞–π—Ç–µ –µ—ë –∫–æ–º–∞–Ω–¥–æ–π: ollama pull {selected_model}")
                    return False
            else:
                st.error("‚ùå Ollama –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω.")
                return False
                
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama: {e}")
            return False
    
    def setup_openrouter(self, model_name: str, api_key: str):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenRouter"""
        if not api_key:
            st.error("‚ùå –í–≤–µ–¥–∏—Ç–µ API –∫–ª—é—á –¥–ª—è OpenRouter")
            return False
            
        model_info = self.available_models["OpenRouter"][model_name]
        
        self.current_provider = "openrouter"
        self.current_model = model_info["path"]
        self.current_model_name = model_name
        self.current_model_params = model_info["params"]
        self.openrouter_key = api_key
        return True

    def generate_response(self, prompt: str, system_prompt: str = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä"""
        if not self.current_provider:
            return "‚ùå –ü—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö."
        
        try:
            if self.current_provider == "huggingface_local":
                return self._generate_huggingface(prompt, system_prompt)
            elif self.current_provider == "ollama":
                return self._generate_ollama(prompt, system_prompt)
            elif self.current_provider == "openrouter":
                return self._generate_openrouter(prompt, system_prompt)
            else:
                return "‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä"
                
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}"
    
    def _generate_huggingface(self, prompt: str, system_prompt: str = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é HuggingFace –º–æ–¥–µ–ª—å"""
        try:
            full_prompt = self._format_prompt(prompt, system_prompt)
            
            outputs = self.current_model(
                full_prompt,
                max_new_tokens=256,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1,
                num_return_sequences=1
            )
            
            response = outputs[0]['generated_text']
            
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞
            if full_prompt in response:
                response = response.replace(full_prompt, "").strip()
            
            return response
            
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ HuggingFace: {str(e)}"
    
    def _generate_ollama(self, prompt: str, system_prompt: str = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Ollama API"""
        try:
            messages = []
            
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            
            messages.append({"role": "user", "content": prompt})
            
            data = {
                "model": self.current_model,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9
                }
            }
            
            response = requests.post(
                f"{self.ollama_url}/api/chat",
                json=data,
                timeout=120
            )
            
            if response.status_code == 200:
                return response.json()["message"]["content"]
            else:
                return f"‚ùå –û—à–∏–±–∫–∞ Ollama: {response.text}"
                
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ Ollama: {str(e)}"
    
    def _generate_openrouter(self, prompt: str, system_prompt: str = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ OpenRouter API"""
        try:
            messages = []
            
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            
            messages.append({"role": "user", "content": prompt})
            
            headers = {
                "Authorization": f"Bearer {self.openrouter_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.current_model,
                "messages": messages,
                "max_tokens": 1000,
                "temperature": 0.7
            }
            
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            else:
                return f"‚ùå –û—à–∏–±–∫–∞ OpenRouter: {response.text}"
                
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ OpenRouter: {str(e)}"
    
    def _format_prompt(self, prompt: str, system_prompt: str = None) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π"""
        if system_prompt:
            return f"{system_prompt}\n\n–í–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞: {prompt}\n\n–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞:"
        else:
            return f"–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: {prompt}\n\n–û—Ç–≤–µ—Ç:"

class CustomMaterialManager:
    def __init__(self, data_manager: DataCollectionManager):
        self.data_manager = data_manager
        self.file_processor = FileProcessor()
        self.custom_materials = []
    
    def create_custom_scenario(self, title: str, topic: str, material: str, description: str = "", file_path: str = None):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è"""
        prompt_id = self.data_manager.get_next_prompt_id()
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
        system_prompt = f"""–¢—ã - AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è. –¢–≤–æ—è —Ä–æ–ª—å - –ø–æ–º–æ–≥–∞—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–∞–º —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è —Å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º –º–∞—Ç–µ—Ä–∏–∞–ª–æ–º.

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
2. –ó–∞–¥–∞–≤–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è
3. –ü—Ä–µ–¥–ª–∞–≥–∞–π —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –¥–ª—è –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞
4. –ë—É–¥—å —Ç–µ—Ä–ø–µ–ª–∏–≤—ã–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º
5. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–º–∫–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞, –≤–µ–∂–ª–∏–≤–æ —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º

–ú–ê–¢–ï–†–ò–ê–õ –î–õ–Ø –ò–ó–£–ß–ï–ù–ò–Ø:
{material}

–ù–∞—á–Ω–∏ —Å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –∏–∑—É—á–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª."""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt_data = {
            "system_prompt_id": prompt_id,
            "system_prompt": system_prompt,
            "description": f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª: {title} - {topic}. {description}",
            "version": "1.0"
        }
        
        self.data_manager.save_system_prompt(system_prompt_data)
        
        scenario = {
            "id": f"custom_{len(self.custom_materials) + 1:03d}",
            "title": title,
            "topic": topic,
            "material": material,
            "system_prompt_id": prompt_id,
            "system_prompt": system_prompt,
            "is_custom": True,
            "description": description,
            "file_path": file_path
        }
        
        self.custom_materials.append(scenario)
        return scenario
    
    def process_uploaded_file(self, uploaded_file) -> tuple:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞"""
        file_type = uploaded_file.type
        filename = uploaded_file.name
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        file_path = self.data_manager.save_uploaded_file(uploaded_file, filename)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        text = ""
        if file_type == "application/pdf":
            text = self.file_processor.extract_text_from_pdf(uploaded_file)
        elif file_type == "text/plain":
            text = self.file_processor.extract_text_from_txt(uploaded_file)
        elif file_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            text = self.file_processor.extract_text_from_docx(uploaded_file)
        else:
            st.error(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_type}")
            return "", ""
        
        return text, file_path

def init_session_state():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏"""
    if 'conversation' not in st.session_state:
        st.session_state.conversation = []
    if 'current_scenario' not in st.session_state:
        st.session_state.current_scenario = None
    if 'nn_manager' not in st.session_state:
        st.session_state.nn_manager = NeuralNetworkManager()
    if 'model_configured' not in st.session_state:
        st.session_state.model_configured = False
    if 'data_manager' not in st.session_state:
        st.session_state.data_manager = DataCollectionManager()
    if 'current_dialog_id' not in st.session_state:
        st.session_state.current_dialog_id = None
    if 'evaluation_mode' not in st.session_state:
        st.session_state.evaluation_mode = False
    if 'material_manager' not in st.session_state:
        st.session_state.material_manager = CustomMaterialManager(st.session_state.data_manager)
    if 'custom_materials' not in st.session_state:
        st.session_state.custom_materials = []
    if 'extracted_text' not in st.session_state:
        st.session_state.extracted_text = None
    if 'file_path' not in st.session_state:
        st.session_state.file_path = None

def main():
    st.set_page_config(
        page_title="AI –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –ù–µ–π—Ä–æ—Å–µ—Ç—è–º–∏",
        page_icon="üß†",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    init_session_state()
    
    # –°–∞–π–¥–±–∞—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –º–æ–¥–µ–ª–µ–π –∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏
    with st.sidebar:
        st.title("üß† –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ù–µ–π—Ä–æ—Å–µ—Ç–∏")
        st.markdown("---")
        
        # –í—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        provider = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞:",
            ["HuggingFace", "Ollama", "OpenRouter", "–î–µ–º–æ-—Ä–µ–∂–∏–º"]
        )
        
        if provider != "–î–µ–º–æ-—Ä–µ–∂–∏–º":
            # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            if provider == "HuggingFace":
                model_name = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
                    list(st.session_state.nn_manager.available_models["HuggingFace"].keys())
                )
                
                st.info("üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏: Qwen-2.5-1.5B –∏–ª–∏ TinyLlama-1.1B")
                
                if st.button("üîÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å", use_container_width=True):
                    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç"):
                        success = st.session_state.nn_manager.setup_huggingface(model_name)
                        if success:
                            st.session_state.model_configured = True
                            st.success(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
                        else:
                            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
            
            elif provider == "Ollama":
                model_name = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
                    list(st.session_state.nn_manager.available_models["Ollama"].keys())
                )
                
                ollama_url = st.text_input("URL Ollama:", "http://localhost:11434")
                
                if st.button("üîó –ü–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama", use_container_width=True):
                    with st.spinner("–ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ..."):
                        success = st.session_state.nn_manager.setup_ollama(model_name, ollama_url)
                        if success:
                            st.session_state.model_configured = True
                            st.success(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ {model_name}!")
                        else:
                            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è")
            
            elif provider == "OpenRouter":
                model_name = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
                    list(st.session_state.nn_manager.available_models["OpenRouter"].keys())
                )
                
                api_key = st.text_input("API Key OpenRouter:", type="password")
                st.markdown("[–ü–æ–ª—É—á–∏—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –∫–ª—é—á](https://openrouter.ai/)")
                
                if st.button("üîë –ü–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ OpenRouter", use_container_width=True):
                    with st.spinner("–ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ..."):
                        success = st.session_state.nn_manager.setup_openrouter(model_name, api_key)
                        if success:
                            st.session_state.model_configured = True
                            st.success(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ {model_name}!")
                        else:
                            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è")
        
        else:
            st.session_state.model_configured = True
            st.session_state.nn_manager.current_provider = "demo"
            st.session_state.nn_manager.current_model_name = "Demo-Model"
            st.session_state.nn_manager.current_model_params = "0B"
            st.info("üî∂ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ–º–æ-—Ä–µ–∂–∏–º –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
        
        st.markdown("---")
        
        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏
        st.subheader("üìö –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏")
        
        # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–ø–æ—Å–æ–±–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
        tab1, tab2 = st.tabs(["üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "üìù –í–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç"])
        
        with tab1:
            st.subheader("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–µ–±–Ω–∏–∫–æ–≤")
            
            uploaded_file = st.file_uploader(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª",
                type=['pdf', 'txt', 'docx'],
                help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è PDF, TXT –∏ DOCX —Ñ–∞–π–ª—ã",
                key="file_uploader"
            )
            
            if uploaded_file is not None:
                st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.name}")
                
                # –ü–æ–ª—è –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                material_title = st.text_input(
                    "–ù–∞–∑–≤–∞–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞:*", 
                    value=uploaded_file.name.split('.')[0],
                    key="file_title"
                )
                material_topic = st.text_input("–¢–µ–º–∞:*", key="file_topic")
                material_description = st.text_area(
                    "–û–ø–∏—Å–∞–Ω–∏–µ:", 
                    placeholder="–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞...",
                    key="file_description"
                )
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("üîç –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞", use_container_width=True):
                        with st.spinner("–ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞..."):
                            text, file_path = st.session_state.material_manager.process_uploaded_file(uploaded_file)
                            
                            if text and len(text.strip()) > 0:
                                st.session_state.extracted_text = text
                                st.session_state.file_path = file_path
                                st.success("‚úÖ –¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω!")
                            else:
                                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é —Ç–µ–∫—Å—Ç–∞ –µ—Å–ª–∏ –æ–Ω –∏–∑–≤–ª–µ—á–µ–Ω
                if st.session_state.extracted_text:
                    st.subheader("üìñ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")
                    preview_length = min(500, len(st.session_state.extracted_text))
                    st.text_area(
                        "–ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤:",
                        value=st.session_state.extracted_text[:preview_length] + "..." if len(st.session_state.extracted_text) > 500 else st.session_state.extracted_text,
                        height=150,
                        disabled=True,
                        key="text_preview"
                    )
                    
                    st.info(f"üìä –ò–∑–≤–ª–µ—á–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(st.session_state.extracted_text)}")
                    
                    with col2:
                        if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª", use_container_width=True, type="primary"):
                            if material_title and material_topic and st.session_state.extracted_text:
                                scenario = st.session_state.material_manager.create_custom_scenario(
                                    material_title, 
                                    material_topic, 
                                    st.session_state.extracted_text, 
                                    material_description, 
                                    st.session_state.file_path
                                )
                                st.session_state.custom_materials.append(scenario)
                                # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                                st.session_state.extracted_text = None
                                st.session_state.file_path = None
                                st.success(f"‚úÖ –ú–∞—Ç–µ—Ä–∏–∞–ª '{material_title}' —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
                                # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
                                st.session_state.data_manager.save_system_prompts_export()
                                st.rerun()
                            else:
                                st.error("‚ùå –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è (–æ—Ç–º–µ—á–µ–Ω—ã *)")
        
        with tab2:
            st.subheader("üìù –†—É—á–Ω–æ–π –≤–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞")
            
            material_title = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞:*", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", key="text_title")
            material_topic = st.text_input("–¢–µ–º–∞:*", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è", key="text_topic")
            material_description = st.text_area("–û–ø–∏—Å–∞–Ω–∏–µ:", placeholder="–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞...", key="text_description")
            material_content = st.text_area(
                "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞:*", 
                placeholder="–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –∑–¥–µ—Å—å...",
                height=200,
                key="text_content"
            )
            
            if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª", use_container_width=True, key="save_text"):
                if material_title and material_topic and material_content:
                    scenario = st.session_state.material_manager.create_custom_scenario(
                        material_title, material_topic, material_content, material_description
                    )
                    st.session_state.custom_materials.append(scenario)
                    st.success(f"‚úÖ –ú–∞—Ç–µ—Ä–∏–∞–ª '{material_title}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
                    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
                    st.session_state.data_manager.save_system_prompts_export()
                    st.rerun()
                else:
                    st.error("‚ùå –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è (–æ—Ç–º–µ—á–µ–Ω—ã *)")
        
        # –í—ã–±–æ—Ä –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è
        st.markdown("---")
        st.subheader("üéØ –í—ã–±–æ—Ä –º–∞—Ç–µ—Ä–∏–∞–ª–∞")
        
        if st.session_state.custom_materials:
            material_options = [f"{s['title']} - {s['topic']}" for s in st.session_state.custom_materials]
            if material_options:
                selected_material = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–∞—Ç–µ—Ä–∏–∞–ª:", material_options, index=0)
                
                # –ù–∞—Ö–æ–¥–∏–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π
                for scenario in st.session_state.custom_materials:
                    if f"{scenario['title']} - {scenario['topic']}" == selected_material:
                        st.session_state.current_scenario = scenario
                        break
                        
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
                st.info(f"üìö –í—Å–µ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤: {len(st.session_state.custom_materials)}")
            else:
                st.info("üìù –î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–π –ø–µ—Ä–≤—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –≤—ã—à–µ")
        else:
            st.info("üìù –î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–π –ø–µ—Ä–≤—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –≤—ã—à–µ")
        
        # –†–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
        st.markdown("---")
        st.subheader("üìä –û—Ü–µ–Ω–∫–∞ –¥–∏–∞–ª–æ–≥–∞")
        st.session_state.evaluation_mode = st.checkbox("–í–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏", value=False)
        
        if st.button("üîÑ –ù–∞—á–∞—Ç—å –Ω–æ–≤—É—é –±–µ—Å–µ–¥—É", use_container_width=True):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –¥–∏–∞–ª–æ–≥ –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            if (st.session_state.conversation and 
                st.session_state.evaluation_mode and 
                st.session_state.current_dialog_id):
                save_current_dialog()
            
            st.session_state.conversation = []
            st.session_state.current_dialog_id = st.session_state.data_manager.get_next_dialog_id()
            st.rerun()
        
        # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
        st.markdown("---")
        st.subheader("üìÅ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üíæ –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö", use_container_width=True):
                with st.spinner("–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ..."):
                    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
                    st.session_state.data_manager.save_system_prompts_export()
                    st.success("‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã!")
        
        with col2:
            if st.button("üìä –ü–æ–∫–∞–∑–∞—Ç—å –æ—Ç—á–µ—Ç", use_container_width=True):
                show_data_report()
        
        st.markdown("---")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∞—Ç—É—Å–µ
        if st.session_state.model_configured:
            if provider == "–î–µ–º–æ-—Ä–µ–∂–∏–º":
                st.warning("üî∂ –î–µ–º–æ-—Ä–µ–∂–∏–º")
            else:
                st.success(f"‚úÖ {provider} –∞–∫—Ç–∏–≤–µ–Ω")
        else:
            st.error("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–∫—É—â–µ–º –¥–∏–∞–ª–æ–≥–µ
        if st.session_state.current_dialog_id:
            st.info(f"üìù –¢–µ–∫—É—â–∏–π –¥–∏–∞–ª–æ–≥: {st.session_state.current_dialog_id}")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    st.title("üß† AI –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –ù–µ–π—Ä–æ—Å–µ—Ç—è–º–∏")
    
    # –ü–∞–Ω–µ–ª—å –æ—Ü–µ–Ω–∫–∏ (—Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏)
    if st.session_state.evaluation_mode and st.session_state.conversation:
        with st.expander("üìä –û—Ü–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π –¥–∏–∞–ª–æ–≥", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                overall_rating = st.slider("–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–∏–∞–ª–æ–≥–∞ (1-10):", 1, 10, 5, key="overall_rating")
            
            with col2:
                evaluation_notes = st.text_area("–ó–∞–º–µ—Ç–∫–∏ –ø–æ –æ—Ü–µ–Ω–∫–µ:", placeholder="–ü–æ–ª–µ–∑–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏ –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∏–∞–ª–æ–≥–∞...", key="evaluation_notes")
            
            if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ü–µ–Ω–∫—É –¥–∏–∞–ª–æ–≥–∞", key="save_evaluation"):
                if st.session_state.current_dialog_id and st.session_state.current_scenario:
                    save_evaluation_summary(overall_rating, evaluation_notes)
                    st.success("‚úÖ –û—Ü–µ–Ω–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
    
    # –ü–æ–∫–∞–∑ —Ç–µ–∫—É—â–µ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
    if st.session_state.current_scenario:
        scenario = st.session_state.current_scenario
        with st.expander("üìñ –¢–µ–∫—É—â–∏–π —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª", expanded=True):
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.markdown(f"**–ù–∞–∑–≤–∞–Ω–∏–µ:** {scenario['title']}")
                st.markdown(f"**–¢–µ–º–∞:** {scenario['topic']}")
                if scenario.get('description'):
                    st.markdown(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {scenario['description']}")
                
                if scenario.get('file_path'):
                    st.info(f"üìé –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {os.path.basename(scenario['file_path'])}")
            
            with col2:
                if st.session_state.evaluation_mode:
                    st.info(f"**ID –ø—Ä–æ–º–ø—Ç–∞:** {scenario['system_prompt_id']}")
            
            st.markdown("---")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø—Ä–æ–∫—Ä—É—Ç–∫–∏
            st.markdown("**–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:**")
            st.text_area(
                "–ú–∞—Ç–µ—Ä–∏–∞–ª",
                value=scenario['material'],
                height=300,
                disabled=True,
                label_visibility="collapsed"
            )
            
            st.info(f"üìä –†–∞–∑–º–µ—Ä –º–∞—Ç–µ—Ä–∏–∞–ª–∞: {len(scenario['material'])} —Å–∏–º–≤–æ–ª–æ–≤")
    else:
        st.info("üëà –î–æ–±–∞–≤—å—Ç–µ —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å")
    
    # –û–±–ª–∞—Å—Ç—å —á–∞—Ç–∞
    st.markdown("---")
    st.subheader("üí≠ –î–∏–∞–ª–æ–≥ —Å AI-–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º")
    
    # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π
    chat_container = st.container()
    with chat_container:
        if not st.session_state.conversation:
            if st.session_state.current_scenario:
                st.info("üí° –ù–∞—á–Ω–∏—Ç–µ –±–µ—Å–µ–¥—É —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–ª–µ –≤–≤–æ–¥–∞ –Ω–∏–∂–µ –∏–ª–∏ –±—ã—Å—Ç—Ä—ã–µ –∫–Ω–æ–ø–∫–∏.")
            else:
                st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤—å—Ç–µ –∏ –≤—ã–±–µ—Ä–∏—Ç–µ —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª")
        
        for i, message in enumerate(st.session_state.conversation):
            if message["role"] == "user":
                with st.chat_message("user"):
                    st.markdown(message["content"])
                    if st.session_state.evaluation_mode and "rating" in message:
                        st.caption(f"–û—Ü–µ–Ω–∫–∞: {message['rating']}/10")
            else:
                with st.chat_message("assistant"):
                    st.markdown(message["content"])
                    if st.session_state.evaluation_mode and "rating" in message:
                        st.caption(f"–û—Ü–µ–Ω–∫–∞: {message['rating']}/10")
            
            # –ö–Ω–æ–ø–∫–∏ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (—Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏)
            if (st.session_state.evaluation_mode and 
                message["role"] == "assistant" and 
                "rating" not in message):
                col1, col2 = st.columns([3, 1])
                with col1:
                    rating = st.slider(
                        f"–û—Ü–µ–Ω–∏—Ç–µ –æ—Ç–≤–µ—Ç #{i//2 + 1}:",
                        1, 10, 5,
                        key=f"rating_{i}"
                    )
                with col2:
                    if st.button(f"üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å", key=f"save_rating_{i}"):
                        message["rating"] = rating
                        st.rerun()
    
    # –ë—ã—Å—Ç—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª)
    if st.session_state.current_scenario:
        st.subheader("üöÄ –ë—ã—Å—Ç—Ä—ã–µ –∑–∞–ø—Ä–æ—Å—ã")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("üìö –û–±—ä—è—Å–Ω–∏ —Ç–µ–º—É", use_container_width=True):
                process_user_message("–û–±—ä—è—Å–Ω–∏ –æ—Å–Ω–æ–≤–Ω—É—é –∫–æ–Ω—Ü–µ–ø—Ü–∏—é —ç—Ç–æ–π —Ç–µ–º—ã")
        
        with col2:
            if st.button("‚ùì –ó–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å—ã", use_container_width=True):
                process_user_message("–ó–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è")
        
        with col3:
            if st.button("üí™ –£–ø—Ä–∞–∂–Ω–µ–Ω–∏—è", use_container_width=True):
                process_user_message("–ü—Ä–µ–¥–ª–æ–∂–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ")
        
        with col4:
            if st.button("üîç –ü—Ä–∏–º–µ—Ä—ã", use_container_width=True):
                process_user_message("–ü—Ä–∏–≤–µ–¥–∏ —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
    
    # –ü–æ–ª–µ –≤–≤–æ–¥–∞
    st.markdown("---")
    user_input = st.chat_input("üí≠ –í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å...")
    
    if user_input:
        process_user_message(user_input)

def process_user_message(user_message: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
    if not st.session_state.current_scenario:
        st.error("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª!")
        return
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –¥–∏–∞–ª–æ–≥–∞ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    if not st.session_state.current_dialog_id:
        st.session_state.current_dialog_id = st.session_state.data_manager.get_next_dialog_id()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_message_data = {
        "turn_number": len(st.session_state.conversation) + 1,
        "role": "user",
        "content": user_message,
        "timestamp": datetime.now().isoformat()
    }
    st.session_state.conversation.append(user_message_data)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    with st.spinner("ü§ñ AI –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç..."):
        scenario = st.session_state.current_scenario
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt = scenario.get("system_prompt", "")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã
        conversation_context = "\n".join([
            f"{'–°—Ç—É–¥–µ–Ω—Ç' if msg['role'] == 'user' else '–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç'}: {msg['content']}" 
            for msg in st.session_state.conversation[-4:]  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        ])
        
        full_prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã:
{conversation_context}

–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞: {user_message}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å –∫–∞–∫ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç:"""
        
        if st.session_state.model_configured and st.session_state.nn_manager.current_provider != "demo":
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å
            response = st.session_state.nn_manager.generate_response(full_prompt, system_prompt)
        else:
            # –î–µ–º–æ-—Ä–µ–∂–∏–º
            response = f"""üß† **–î–µ–º–æ-–æ—Ç–≤–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏**

–í —Ä–µ–∞–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã –æ—Ç–≤–µ—Ç –æ—Ç AI-–º–æ–¥–µ–ª–∏.

**–í–∞—à –≤–æ–ø—Ä–æ—Å:** "{user_message}"

**–í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ç–µ–º—ã:** {st.session_state.current_scenario['topic']}

*–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.*"""
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    assistant_message_data = {
        "turn_number": len(st.session_state.conversation) + 1,
        "role": "assistant", 
        "content": response,
        "timestamp": datetime.now().isoformat(),
        "model_response": response
    }
    st.session_state.conversation.append(assistant_message_data)
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ª–æ–≥ –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏
    if st.session_state.evaluation_mode:
        save_dialog_to_file()
    
    st.rerun()

def save_dialog_to_file():
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ –≤ —Ñ–∞–π–ª"""
    if not st.session_state.current_dialog_id:
        return
    
    dialog_data = []
    for msg in st.session_state.conversation:
        dialog_data.append({
            "turn_number": msg["turn_number"],
            "role": msg["role"],
            "content": msg["content"],
            "model_response": msg.get("model_response", ""),
            "rating": msg.get("rating", None)
        })
    
    success = st.session_state.data_manager.save_dialog_data(
        st.session_state.current_dialog_id, 
        dialog_data
    )
    
    if success:
        st.success(f"‚úÖ –î–∏–∞–ª–æ–≥ {st.session_state.current_dialog_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")

def save_evaluation_summary(overall_rating: int, evaluation_notes: str):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏ –¥–∏–∞–ª–æ–≥–∞"""
    if not all([st.session_state.current_dialog_id, 
                st.session_state.current_scenario,
                st.session_state.nn_manager.current_model_name]):
        st.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏")
        return
    
    summary_data = {
        "model_name": st.session_state.nn_manager.current_model_name,
        "model_parameters": st.session_state.nn_manager.current_model_params,
        "lecture_title": st.session_state.current_scenario["title"],
        "lecture_topic": st.session_state.current_scenario["topic"],
        "system_prompt_id": st.session_state.current_scenario["system_prompt_id"],
        "dialog_id": st.session_state.current_dialog_id,
        "overall_rating": overall_rating,
        "evaluation_notes": evaluation_notes
    }
    
    success = st.session_state.data_manager.save_evaluation_summary(summary_data)
    if success:
        st.session_state.data_manager.save_system_prompts_export()

def save_current_dialog():
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
    if st.session_state.conversation and st.session_state.current_dialog_id:
        save_dialog_to_file()

def show_data_report():
    """–ü–æ–∫–∞–∑–∞—Ç—å –æ—Ç—á–µ—Ç –ø–æ —Å–æ–±—Ä–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º"""
    try:
        st.subheader("üìä –û—Ç—á–µ—Ç –ø–æ —Å–æ–±—Ä–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º")
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª –æ—Ç—á–µ—Ç–∞
        if os.path.exists(st.session_state.data_manager.summary_file):
            df_summary = pd.read_csv(st.session_state.data_manager.summary_file)
            st.write("**–û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç—á–µ—Ç:**")
            st.dataframe(df_summary)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤", len(df_summary))
            with col2:
                if 'overall_rating' in df_summary.columns:
                    avg_rating = df_summary['overall_rating'].mean()
                    st.metric("–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞", f"{avg_rating:.2f}")
            with col3:
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", df_summary['model_name'].nunique())
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        prompts = st.session_state.data_manager.get_all_system_prompts()
        if prompts:
            st.write("**–°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã:**")
            st.dataframe(pd.DataFrame(prompts))
        
        # –î–∏–∞–ª–æ–≥–∏
        if os.path.exists(st.session_state.data_manager.dialogs_dir):
            dialog_files = [f for f in os.listdir(st.session_state.data_manager.dialogs_dir) if f.endswith('.json')]
            st.write(f"**–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∏:** {len(dialog_files)}")
            
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç—á–µ—Ç–∞: {e}")

if __name__ == "__main__":
    main()